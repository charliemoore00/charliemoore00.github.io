{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Implementing Logistic Regression [in progress]\n",
    "author: Charlie Moore\n",
    "date: '2024-05-12'\n",
    "image: \"image.jpg\"\n",
    "description: \"'Implementing Logistic Regression\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from logistic import LogisticRegression, GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Recently, we introduced the gradient descent algorithm for solving the empirical risk minimization problem. We also calculated the gradient of the loss function for logistic regression.\n",
    "\n",
    "In this blog post you will:\n",
    "\n",
    "Implement gradient descent for logistic regression in an object-oriented paradigm.\n",
    "Implement a key variant of gradient descent with momentum in order to achieve faster convergence.\n",
    "Perform experiments to test your implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Implement Logistic Regression\n",
    "\n",
    "## Implement ``LinearModel`` and ``LogisticRegression()``\n",
    "If you havenâ€™t already, implement the methods of the ``LinearModel`` class as described in this warmup. Then, define a new class called ``LogisticRegression`` which inherits from ``LinearModel``. This class should have two methods:\n",
    "\n",
    "- ``LogisticRegression.loss(X, y)`` should compute the empirical risk $L(w)$ using the logistic loss function. The weight vector ``w`` used for this calculation should be stored as an instance variable of the class.\n",
    "\n",
    "- ``LogisticRegression.grad(X, y)`` should compute the gradient of the empirical risk $L(w)$. You can use the formula for the gradient supplied in the lecture notes on gradient descent.\n",
    "\n",
    "For an **M**, you can implement ``LogisticRegression.grad`` using a ``for``-loop. For an **E**, your solution should involve no explicit loops. While working on a solution that avoids loops, you might find it useful to at some point convert a tensor ``v`` with shape ``(n,)`` into a tensor ``v_`` with shape ``(n,1)``. The code ``v_ = v[:, None]`` will perform this conversion for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement ``GradientDescentOptimizer``\n",
    "\n",
    "Next, implement a ``GradientDescentOptimizer`` class. For this project, we are going to implement _gradient descent with momentum_, also known as Spicy Gradient Descent. Let w~k~ be the estimate of the weight vector at algorithmic step k. Gradient descent with momentum performs the update equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Experiments\n",
    "\n",
    "## Experimental Data\n",
    "\n",
    "## How to Train Your Model\n",
    "\n",
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C: Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4734)\n",
      "tensor([-0.0369, -0.0554,  0.1729])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "logistic.py\n",
    "\n",
    "implements \n",
    "- LinearModel\n",
    "- LogisticRegression which inherits from LinearModel\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "class LinearModel:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.w = None \n",
    "\n",
    "    def score(self, X):\n",
    "        \"\"\"\n",
    "        Compute the scores for each data point in the feature matrix X. \n",
    "        The formula for the ith entry of s is s[i] = <self.w, x[i]>. \n",
    "\n",
    "        ARGUMENTS: \n",
    "            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n",
    "            where n is the number of data points and p is the \n",
    "            number of features. This implementation always assumes \n",
    "            that the final column of X is a constant column of 1s. \n",
    "\n",
    "        RETURNS: \n",
    "            s torch.Tensor: vector of scores. s.size() = (n,)\n",
    "\n",
    "        If self.w currently has value None, then it is necessary to first initialize self.w to a random value. \n",
    "        \"\"\"\n",
    "        if self.w is None: \n",
    "            self.w = torch.rand((X.size()[1]))\n",
    "        \n",
    "        return X@self.w\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        \"\"\"\n",
    "        Compute the predictions for each data point in the feature matrix X. \n",
    "        The prediction for the ith data point is either 0 or 1. \n",
    "\n",
    "        ARGUMENTS: \n",
    "            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n",
    "            where n is the number of data points and p is the \n",
    "            number of features. This implementation always assumes \n",
    "            that the final column of X is a constant column of 1s. \n",
    "\n",
    "        RETURNS: \n",
    "            y_hat, torch.Tensor: vector predictions in {0.0, 1.0}. y_hat.size() = (n,)\n",
    "        \"\"\"\n",
    "        s = self.score(X)\n",
    "        return (s > 0).int()\n",
    "        \n",
    "        pass \n",
    "\n",
    "\n",
    "\n",
    "class LogisticRegression(LinearModel):\n",
    "    \n",
    "    def loss(self, X, y):\n",
    "\n",
    "        \"\"\"\n",
    "        Computes the empirical risk L(w) using the logistic loss function\n",
    "\n",
    "        ARGUMENTS:\n",
    "            X, torch.Tensor: the feature matrix. X.size() == (n, p),\n",
    "            where n is the number of data points and p is the \n",
    "            number of features. This implementation always assumes\n",
    "            that the final column of X is a constant column of 1s.\n",
    "\n",
    "            y, torch.Tensor: the target vector. y.size() = (n,). \n",
    "            The Possible labels for y are {0, 1}\n",
    "\n",
    "        RETURNS:\n",
    "            the empirical risk L(w)\n",
    "            equation:\n",
    "            mean[-yi log(sigmoid(si)) - (1-yi)log(1-sigmoid(si))]\n",
    "        \"\"\"\n",
    "\n",
    "        self.score(X)                   # call our score function to get the weights w\n",
    "        scores = X @ self.w             # get our score vector s to use in the logistic loss function\n",
    "        def sigmoid(z):                 # implementation of sigmoid function\n",
    "            return 1/(1 + torch.exp(-z))\n",
    "\n",
    "        # use the logistic loss function to calculate L(w)!\n",
    "        loss = torch.mean(-y * torch.log(sigmoid(scores)) - (1 - y) * torch.log(1 - sigmoid(scores)))\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def grad(self, X, y):\n",
    "        \n",
    "        \"\"\"\n",
    "        Computes the gradient of the empirical risk L(w)\n",
    "\n",
    "        ARGUMENTS: \n",
    "            X, torch.Tensor: the feature matrix. X.size() == (n, p),\n",
    "            where n is the number of data points and p is the \n",
    "            number of features. This implementation always assumes \n",
    "            that the final column of X is a constant column of 1s. \n",
    "\n",
    "            y, torch.Tensor: the target vector. y.size() == (n,).\n",
    "            The possible labels for y are {0, 1}\n",
    "\n",
    "        RETURNS:\n",
    "            the gradient of the empirical risk L(w)\n",
    "            equation:\n",
    "            change of L(w) = mean(sigmoid(si) - yi)xi\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        y_ = y[:, None]                 # convert tensor with shape (n,) to shape (n,1)\n",
    "\n",
    "        self.score(X)                   # call our score function to get the weights w\n",
    "        scores = X @ self.w             # get our score vector s to use in the logistic loss function\n",
    "        scores = scores[:, None]\n",
    "        def sigmoid(z):                 # implementation of sigmoid function\n",
    "            return 1/(1 + torch.exp(-z))\n",
    "        \n",
    "        #print(y_.shape)\n",
    "        #print((sigmoid(scores) - y_).shape)\n",
    "        #print(X.shape)\n",
    "        \n",
    "        gradients = (sigmoid(scores) - y_) * X\n",
    "        gradient = torch.mean(gradients, dim=0)\n",
    "        return gradient\n",
    "\n",
    "\n",
    "\n",
    "class GradientDescentOptimizer():\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.w_old = None\n",
    "\n",
    "    def step(self, X, y, alpha, beta):\n",
    "\n",
    "        \"\"\"\n",
    "        Implements Gradient Descent with Momentum\n",
    "        It performs an update of the weights w\n",
    "\n",
    "        ARGUMENTS:\n",
    "            X, torch.Tensor: the feature matrix\n",
    "\n",
    "            y, torch.Tensor: the target vector\n",
    "\n",
    "            alpha\n",
    "\n",
    "            beta\n",
    "\n",
    "        RETURNS:\n",
    "            Nothing\n",
    "            Updates the weights self.model.w\n",
    "            Use equation:\n",
    "            Wk+1 <-- Wk - alpha(grad(Wk)) + beta(Wk - Wk+1)\n",
    "        \"\"\"\n",
    "\n",
    "        gradient = self.model.grad(X, y)\n",
    "        w = self.model.w\n",
    "        #if self.w_old is None:\n",
    "            #self.w_old = torch.zeros_like(w)\n",
    "\n",
    "        new_weights = w - alpha*gradient\n",
    "\n",
    "        if self.w_old != None:\n",
    "            new_weights += beta*(w - self.w_old)\n",
    "        \n",
    "        #new_weights = w - alpha*gradient + beta*(w - self.w_old)\n",
    "        self.w_old = w.clone()\n",
    "        self.model.w = new_weights\n",
    "        print(new_weights)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# TESTING\n",
    "def classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n",
    "    \n",
    "    y = torch.arange(n_points) >= int(n_points/2)\n",
    "    y = 1.0*y\n",
    "    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n",
    "    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = classification_data(noise = 0.5)\n",
    "\n",
    "LR = LogisticRegression()\n",
    "opt = GradientDescentOptimizer(LR)\n",
    "s = LR.loss(X, y)\n",
    "g = LR.grad(X, y)\n",
    "print(s)\n",
    "print(g)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0904, 0.1831, 1.7245])\n",
      "tensor([0.1414, 0.2763, 2.4127])\n",
      "tensor([0.1904, 0.3658, 2.9891])\n",
      "tensor([0.2365, 0.4506, 3.4619])\n",
      "tensor([0.2793, 0.5308, 3.8398])\n",
      "tensor([0.3189, 0.6065, 4.1315])\n",
      "tensor([0.3556, 0.6783, 4.3453])\n",
      "tensor([0.3896, 0.7463, 4.4887])\n",
      "tensor([0.4210, 0.8110, 4.5686])\n",
      "tensor([0.4501, 0.8725, 4.5913])\n",
      "tensor([0.4772, 0.9313, 4.5625])\n",
      "tensor([0.5024, 0.9876, 4.4874])\n",
      "tensor([0.5258, 1.0416, 4.3706])\n",
      "tensor([0.5477, 1.0935, 4.2165])\n",
      "tensor([0.5681, 1.1435, 4.0289])\n",
      "tensor([0.5873, 1.1916, 3.8114])\n",
      "tensor([0.6052, 1.2381, 3.5674])\n",
      "tensor([0.6219, 1.2829, 3.2999])\n",
      "tensor([0.6376, 1.3260, 3.0120])\n",
      "tensor([0.6522, 1.3675, 2.7066])\n",
      "tensor([0.6656, 1.4072, 2.3866])\n",
      "tensor([0.6780, 1.4449, 2.0552])\n",
      "tensor([0.6892, 1.4804, 1.7155])\n",
      "tensor([0.6993, 1.5135, 1.3712])\n",
      "tensor([0.7083, 1.5441, 1.0258])\n",
      "tensor([0.7165, 1.5720, 0.6834])\n",
      "tensor([0.7243, 1.5976, 0.3478])\n",
      "tensor([0.7324, 1.6211, 0.0231])\n",
      "tensor([ 0.7416,  1.6433, -0.2872])\n",
      "tensor([ 0.7531,  1.6653, -0.5799])\n",
      "tensor([ 0.7680,  1.6881, -0.8521])\n",
      "tensor([ 0.7874,  1.7129, -1.1018])\n",
      "tensor([ 0.8124,  1.7409, -1.3275])\n",
      "tensor([ 0.8438,  1.7731, -1.5285])\n",
      "tensor([ 0.8820,  1.8101, -1.7045])\n",
      "tensor([ 0.9274,  1.8524, -1.8560])\n",
      "tensor([ 0.9798,  1.9001, -1.9840])\n",
      "tensor([ 1.0386,  1.9529, -2.0898])\n",
      "tensor([ 1.1032,  2.0103, -2.1752])\n",
      "tensor([ 1.1726,  2.0716, -2.2422])\n",
      "tensor([ 1.2458,  2.1359, -2.2928])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.3217,  2.2024, -2.3292])\n",
      "tensor([ 1.3991,  2.2700, -2.3534])\n",
      "tensor([ 1.4771,  2.3380, -2.3676])\n",
      "tensor([ 1.5546,  2.4054, -2.3736])\n",
      "tensor([ 1.6308,  2.4715, -2.3732])\n",
      "tensor([ 1.7050,  2.5356, -2.3679])\n",
      "tensor([ 1.7765,  2.5974, -2.3593])\n",
      "tensor([ 1.8449,  2.6563, -2.3484])\n",
      "tensor([ 1.9098,  2.7120, -2.3363])\n",
      "tensor([ 1.9711,  2.7644, -2.3238])\n",
      "tensor([ 2.0284,  2.8133, -2.3118])\n",
      "tensor([ 2.0819,  2.8587, -2.3006])\n",
      "tensor([ 2.1314,  2.9006, -2.2909])\n",
      "tensor([ 2.1770,  2.9390, -2.2828])\n",
      "tensor([ 2.2188,  2.9740, -2.2767])\n",
      "tensor([ 2.2569,  3.0057, -2.2727])\n",
      "tensor([ 2.2915,  3.0342, -2.2709])\n",
      "tensor([ 2.3227,  3.0599, -2.2714])\n",
      "tensor([ 2.3508,  3.0826, -2.2740])\n",
      "tensor([ 2.3758,  3.1028, -2.2787])\n",
      "tensor([ 2.3981,  3.1205, -2.2855])\n",
      "tensor([ 2.4178,  3.1360, -2.2942])\n",
      "tensor([ 2.4352,  3.1494, -2.3046])\n",
      "tensor([ 2.4503,  3.1608, -2.3167])\n",
      "tensor([ 2.4635,  3.1706, -2.3302])\n",
      "tensor([ 2.4748,  3.1788, -2.3450])\n",
      "tensor([ 2.4845,  3.1856, -2.3608])\n",
      "tensor([ 2.4928,  3.1912, -2.3776])\n",
      "tensor([ 2.4998,  3.1956, -2.3950])\n",
      "tensor([ 2.5057,  3.1992, -2.4131])\n",
      "tensor([ 2.5107,  3.2019, -2.4315])\n",
      "tensor([ 2.5147,  3.2040, -2.4501])\n",
      "tensor([ 2.5181,  3.2055, -2.4689])\n",
      "tensor([ 2.5209,  3.2065, -2.4876])\n",
      "tensor([ 2.5232,  3.2072, -2.5061])\n",
      "tensor([ 2.5252,  3.2076, -2.5243])\n",
      "tensor([ 2.5268,  3.2079, -2.5421])\n",
      "tensor([ 2.5283,  3.2080, -2.5594])\n",
      "tensor([ 2.5297,  3.2081, -2.5762])\n",
      "tensor([ 2.5310,  3.2082, -2.5923])\n",
      "tensor([ 2.5323,  3.2084, -2.6077])\n",
      "tensor([ 2.5337,  3.2087, -2.6224])\n",
      "tensor([ 2.5351,  3.2092, -2.6363])\n",
      "tensor([ 2.5367,  3.2098, -2.6494])\n",
      "tensor([ 2.5385,  3.2107, -2.6617])\n",
      "tensor([ 2.5404,  3.2118, -2.6732])\n",
      "tensor([ 2.5425,  3.2131, -2.6839])\n",
      "tensor([ 2.5448,  3.2146, -2.6938])\n",
      "tensor([ 2.5474,  3.2165, -2.7029])\n",
      "tensor([ 2.5501,  3.2185, -2.7113])\n",
      "tensor([ 2.5530,  3.2208, -2.7189])\n",
      "tensor([ 2.5562,  3.2233, -2.7258])\n",
      "tensor([ 2.5595,  3.2260, -2.7321])\n",
      "tensor([ 2.5630,  3.2290, -2.7377])\n",
      "tensor([ 2.5667,  3.2321, -2.7428])\n",
      "tensor([ 2.5705,  3.2354, -2.7473])\n",
      "tensor([ 2.5745,  3.2389, -2.7514])\n",
      "tensor([ 2.5785,  3.2425, -2.7550])\n",
      "tensor([ 2.5827,  3.2462, -2.7582])\n",
      "tensor([ 2.5869,  3.2500, -2.7610])\n",
      "tensor([ 2.5912,  3.2539, -2.7636])\n",
      "tensor([ 2.5955,  3.2579, -2.7658])\n",
      "tensor([ 2.5999,  3.2618, -2.7679])\n",
      "tensor([ 2.6042,  3.2659, -2.7697])\n",
      "tensor([ 2.6086,  3.2699, -2.7714])\n",
      "tensor([ 2.6129,  3.2739, -2.7730])\n",
      "tensor([ 2.6172,  3.2779, -2.7745])\n",
      "tensor([ 2.6214,  3.2819, -2.7759])\n",
      "tensor([ 2.6256,  3.2859, -2.7772])\n",
      "tensor([ 2.6297,  3.2898, -2.7786])\n",
      "tensor([ 2.6337,  3.2936, -2.7799])\n",
      "tensor([ 2.6376,  3.2973, -2.7813])\n",
      "tensor([ 2.6414,  3.3010, -2.7827])\n",
      "tensor([ 2.6452,  3.3046, -2.7841])\n",
      "tensor([ 2.6488,  3.3082, -2.7856])\n",
      "tensor([ 2.6524,  3.3116, -2.7872])\n",
      "tensor([ 2.6558,  3.3149, -2.7888])\n",
      "tensor([ 2.6591,  3.3182, -2.7906])\n",
      "tensor([ 2.6624,  3.3214, -2.7923])\n",
      "tensor([ 2.6655,  3.3245, -2.7942])\n",
      "tensor([ 2.6685,  3.3275, -2.7962])\n",
      "tensor([ 2.6714,  3.3304, -2.7982])\n",
      "tensor([ 2.6743,  3.3332, -2.8003])\n",
      "tensor([ 2.6770,  3.3359, -2.8025])\n",
      "tensor([ 2.6797,  3.3386, -2.8047])\n",
      "tensor([ 2.6822,  3.3412, -2.8070])\n",
      "tensor([ 2.6847,  3.3437, -2.8094])\n",
      "tensor([ 2.6871,  3.3461, -2.8118])\n",
      "tensor([ 2.6895,  3.3485, -2.8143])\n",
      "tensor([ 2.6917,  3.3509, -2.8168])\n",
      "tensor([ 2.6939,  3.3531, -2.8193])\n",
      "tensor([ 2.6961,  3.3554, -2.8219])\n",
      "tensor([ 2.6982,  3.3575, -2.8244])\n",
      "tensor([ 2.7002,  3.3597, -2.8270])\n",
      "tensor([ 2.7022,  3.3618, -2.8296])\n",
      "tensor([ 2.7041,  3.3638, -2.8322])\n",
      "tensor([ 2.7061,  3.3658, -2.8348])\n",
      "tensor([ 2.7079,  3.3678, -2.8374])\n",
      "tensor([ 2.7098,  3.3698, -2.8400])\n",
      "tensor([ 2.7116,  3.3718, -2.8425])\n",
      "tensor([ 2.7134,  3.3737, -2.8451])\n",
      "tensor([ 2.7152,  3.3756, -2.8476])\n",
      "tensor([ 2.7169,  3.3775, -2.8500])\n",
      "tensor([ 2.7186,  3.3793, -2.8525])\n",
      "tensor([ 2.7203,  3.3812, -2.8549])\n",
      "tensor([ 2.7220,  3.3830, -2.8573])\n",
      "tensor([ 2.7237,  3.3849, -2.8596])\n",
      "tensor([ 2.7254,  3.3867, -2.8619])\n",
      "tensor([ 2.7271,  3.3885, -2.8642])\n",
      "tensor([ 2.7287,  3.3903, -2.8664])\n",
      "tensor([ 2.7303,  3.3921, -2.8686])\n",
      "tensor([ 2.7320,  3.3939, -2.8707])\n",
      "tensor([ 2.7336,  3.3957, -2.8729])\n",
      "tensor([ 2.7352,  3.3975, -2.8749])\n",
      "tensor([ 2.7368,  3.3993, -2.8769])\n",
      "tensor([ 2.7384,  3.4010, -2.8789])\n",
      "tensor([ 2.7400,  3.4028, -2.8809])\n",
      "tensor([ 2.7416,  3.4045, -2.8828])\n",
      "tensor([ 2.7431,  3.4063, -2.8847])\n",
      "tensor([ 2.7447,  3.4080, -2.8865])\n",
      "tensor([ 2.7462,  3.4097, -2.8883])\n",
      "tensor([ 2.7478,  3.4115, -2.8901])\n",
      "tensor([ 2.7493,  3.4132, -2.8919])\n",
      "tensor([ 2.7508,  3.4149, -2.8936])\n",
      "tensor([ 2.7523,  3.4165, -2.8953])\n",
      "tensor([ 2.7538,  3.4182, -2.8969])\n",
      "tensor([ 2.7553,  3.4199, -2.8986])\n",
      "tensor([ 2.7567,  3.4215, -2.9002])\n",
      "tensor([ 2.7582,  3.4232, -2.9018])\n",
      "tensor([ 2.7596,  3.4248, -2.9034])\n",
      "tensor([ 2.7611,  3.4264, -2.9050])\n",
      "tensor([ 2.7625,  3.4280, -2.9065])\n",
      "tensor([ 2.7639,  3.4296, -2.9080])\n",
      "tensor([ 2.7653,  3.4312, -2.9095])\n",
      "tensor([ 2.7666,  3.4328, -2.9110])\n",
      "tensor([ 2.7680,  3.4343, -2.9125])\n",
      "tensor([ 2.7693,  3.4358, -2.9140])\n",
      "tensor([ 2.7707,  3.4374, -2.9154])\n",
      "tensor([ 2.7720,  3.4389, -2.9168])\n",
      "tensor([ 2.7733,  3.4403, -2.9183])\n",
      "tensor([ 2.7746,  3.4418, -2.9197])\n",
      "tensor([ 2.7758,  3.4433, -2.9211])\n",
      "tensor([ 2.7771,  3.4447, -2.9225])\n",
      "tensor([ 2.7783,  3.4462, -2.9238])\n",
      "tensor([ 2.7795,  3.4476, -2.9252])\n",
      "tensor([ 2.7807,  3.4490, -2.9266])\n",
      "tensor([ 2.7819,  3.4504, -2.9279])\n",
      "tensor([ 2.7831,  3.4517, -2.9293])\n",
      "tensor([ 2.7843,  3.4531, -2.9306])\n",
      "tensor([ 2.7854,  3.4544, -2.9319])\n",
      "tensor([ 2.7866,  3.4558, -2.9332])\n",
      "tensor([ 2.7877,  3.4571, -2.9345])\n",
      "tensor([ 2.7888,  3.4584, -2.9358])\n",
      "tensor([ 2.7899,  3.4597, -2.9371])\n",
      "tensor([ 2.7910,  3.4610, -2.9383])\n",
      "tensor([ 2.7921,  3.4622, -2.9396])\n",
      "tensor([ 2.7932,  3.4635, -2.9408])\n",
      "tensor([ 2.7942,  3.4647, -2.9421])\n",
      "tensor([ 2.7953,  3.4660, -2.9433])\n",
      "tensor([ 2.7963,  3.4672, -2.9445])\n",
      "tensor([ 2.7973,  3.4684, -2.9457])\n",
      "tensor([ 2.7983,  3.4696, -2.9469])\n",
      "tensor([ 2.7993,  3.4708, -2.9481])\n",
      "tensor([ 2.8003,  3.4719, -2.9493])\n",
      "tensor([ 2.8013,  3.4731, -2.9505])\n",
      "tensor([ 2.8023,  3.4743, -2.9516])\n",
      "tensor([ 2.8032,  3.4754, -2.9528])\n",
      "tensor([ 2.8042,  3.4765, -2.9539])\n",
      "tensor([ 2.8051,  3.4776, -2.9550])\n",
      "tensor([ 2.8060,  3.4788, -2.9561])\n",
      "tensor([ 2.8069,  3.4799, -2.9572])\n",
      "tensor([ 2.8079,  3.4810, -2.9583])\n",
      "tensor([ 2.8088,  3.4820, -2.9594])\n",
      "tensor([ 2.8097,  3.4831, -2.9605])\n",
      "tensor([ 2.8105,  3.4842, -2.9615])\n",
      "tensor([ 2.8114,  3.4852, -2.9626])\n",
      "tensor([ 2.8123,  3.4863, -2.9636])\n",
      "tensor([ 2.8131,  3.4873, -2.9646])\n",
      "tensor([ 2.8140,  3.4883, -2.9657])\n",
      "tensor([ 2.8148,  3.4893, -2.9667])\n",
      "tensor([ 2.8157,  3.4903, -2.9677])\n",
      "tensor([ 2.8165,  3.4913, -2.9687])\n",
      "tensor([ 2.8173,  3.4923, -2.9696])\n",
      "tensor([ 2.8181,  3.4933, -2.9706])\n",
      "tensor([ 2.8189,  3.4943, -2.9716])\n",
      "tensor([ 2.8197,  3.4953, -2.9725])\n",
      "tensor([ 2.8205,  3.4962, -2.9735])\n",
      "tensor([ 2.8213,  3.4972, -2.9744])\n",
      "tensor([ 2.8221,  3.4981, -2.9753])\n",
      "tensor([ 2.8228,  3.4990, -2.9762])\n",
      "tensor([ 2.8236,  3.5000, -2.9772])\n",
      "tensor([ 2.8244,  3.5009, -2.9781])\n",
      "tensor([ 2.8251,  3.5018, -2.9789])\n",
      "tensor([ 2.8258,  3.5027, -2.9798])\n",
      "tensor([ 2.8266,  3.5036, -2.9807])\n",
      "tensor([ 2.8273,  3.5045, -2.9816])\n",
      "tensor([ 2.8280,  3.5054, -2.9824])\n",
      "tensor([ 2.8287,  3.5062, -2.9833])\n",
      "tensor([ 2.8294,  3.5071, -2.9841])\n",
      "tensor([ 2.8301,  3.5079, -2.9849])\n",
      "tensor([ 2.8308,  3.5088, -2.9858])\n",
      "tensor([ 2.8315,  3.5096, -2.9866])\n",
      "tensor([ 2.8322,  3.5105, -2.9874])\n",
      "tensor([ 2.8329,  3.5113, -2.9882])\n",
      "tensor([ 2.8335,  3.5121, -2.9890])\n",
      "tensor([ 2.8342,  3.5129, -2.9898])\n",
      "tensor([ 2.8348,  3.5137, -2.9906])\n",
      "tensor([ 2.8355,  3.5145, -2.9913])\n",
      "tensor([ 2.8361,  3.5153, -2.9921])\n",
      "tensor([ 2.8368,  3.5161, -2.9929])\n",
      "tensor([ 2.8374,  3.5169, -2.9936])\n",
      "tensor([ 2.8380,  3.5176, -2.9944])\n",
      "tensor([ 2.8386,  3.5184, -2.9951])\n",
      "tensor([ 2.8392,  3.5191, -2.9958])\n",
      "tensor([ 2.8399,  3.5199, -2.9966])\n",
      "tensor([ 2.8405,  3.5206, -2.9973])\n",
      "tensor([ 2.8410,  3.5214, -2.9980])\n",
      "tensor([ 2.8416,  3.5221, -2.9987])\n",
      "tensor([ 2.8422,  3.5228, -2.9994])\n",
      "tensor([ 2.8428,  3.5235, -3.0001])\n",
      "tensor([ 2.8434,  3.5243, -3.0008])\n",
      "tensor([ 2.8439,  3.5250, -3.0015])\n",
      "tensor([ 2.8445,  3.5257, -3.0022])\n",
      "tensor([ 2.8451,  3.5263, -3.0028])\n",
      "tensor([ 2.8456,  3.5270, -3.0035])\n",
      "tensor([ 2.8462,  3.5277, -3.0042])\n",
      "tensor([ 2.8467,  3.5284, -3.0048])\n",
      "tensor([ 2.8472,  3.5291, -3.0055])\n",
      "tensor([ 2.8478,  3.5297, -3.0061])\n",
      "tensor([ 2.8483,  3.5304, -3.0067])\n",
      "tensor([ 2.8488,  3.5310, -3.0074])\n",
      "tensor([ 2.8493,  3.5317, -3.0080])\n",
      "tensor([ 2.8499,  3.5323, -3.0086])\n",
      "tensor([ 2.8504,  3.5329, -3.0092])\n",
      "tensor([ 2.8509,  3.5336, -3.0098])\n",
      "tensor([ 2.8514,  3.5342, -3.0104])\n",
      "tensor([ 2.8519,  3.5348, -3.0110])\n",
      "tensor([ 2.8523,  3.5354, -3.0116])\n",
      "tensor([ 2.8528,  3.5360, -3.0122])\n",
      "tensor([ 2.8533,  3.5366, -3.0128])\n",
      "tensor([ 2.8538,  3.5372, -3.0134])\n",
      "tensor([ 2.8543,  3.5378, -3.0139])\n",
      "tensor([ 2.8547,  3.5384, -3.0145])\n",
      "tensor([ 2.8552,  3.5390, -3.0151])\n",
      "tensor([ 2.8557,  3.5395, -3.0156])\n",
      "tensor([ 2.8561,  3.5401, -3.0162])\n",
      "tensor([ 2.8566,  3.5407, -3.0167])\n",
      "tensor([ 2.8570,  3.5412, -3.0173])\n",
      "tensor([ 2.8575,  3.5418, -3.0178])\n",
      "tensor([ 2.8579,  3.5424, -3.0183])\n",
      "tensor([ 2.8583,  3.5429, -3.0189])\n",
      "tensor([ 2.8588,  3.5434, -3.0194])\n",
      "tensor([ 2.8592,  3.5440, -3.0199])\n",
      "tensor([ 2.8596,  3.5445, -3.0204])\n",
      "tensor([ 2.8600,  3.5450, -3.0209])\n",
      "tensor([ 2.8604,  3.5456, -3.0214])\n",
      "tensor([ 2.8609,  3.5461, -3.0219])\n",
      "tensor([ 2.8613,  3.5466, -3.0224])\n",
      "tensor([ 2.8617,  3.5471, -3.0229])\n",
      "tensor([ 2.8621,  3.5476, -3.0234])\n",
      "tensor([ 2.8625,  3.5481, -3.0239])\n",
      "tensor([ 2.8629,  3.5486, -3.0244])\n",
      "tensor([ 2.8633,  3.5491, -3.0249])\n",
      "tensor([ 2.8636,  3.5496, -3.0253])\n",
      "tensor([ 2.8640,  3.5501, -3.0258])\n",
      "tensor([ 2.8644,  3.5506, -3.0263])\n",
      "tensor([ 2.8648,  3.5510, -3.0267])\n",
      "tensor([ 2.8652,  3.5515, -3.0272])\n",
      "tensor([ 2.8655,  3.5520, -3.0276])\n",
      "tensor([ 2.8659,  3.5524, -3.0281])\n",
      "tensor([ 2.8663,  3.5529, -3.0285])\n",
      "tensor([ 2.8666,  3.5533, -3.0289])\n",
      "tensor([ 2.8670,  3.5538, -3.0294])\n",
      "tensor([ 2.8673,  3.5542, -3.0298])\n",
      "tensor([ 2.8677,  3.5547, -3.0302])\n",
      "tensor([ 2.8680,  3.5551, -3.0307])\n",
      "tensor([ 2.8684,  3.5556, -3.0311])\n",
      "tensor([ 2.8687,  3.5560, -3.0315])\n",
      "tensor([ 2.8691,  3.5564, -3.0319])\n",
      "tensor([ 2.8694,  3.5568, -3.0323])\n",
      "tensor([ 2.8697,  3.5573, -3.0327])\n",
      "tensor([ 2.8701,  3.5577, -3.0331])\n",
      "tensor([ 2.8704,  3.5581, -3.0335])\n",
      "tensor([ 2.8707,  3.5585, -3.0339])\n",
      "tensor([ 2.8710,  3.5589, -3.0343])\n",
      "tensor([ 2.8713,  3.5593, -3.0347])\n",
      "tensor([ 2.8717,  3.5597, -3.0351])\n",
      "tensor([ 2.8720,  3.5601, -3.0355])\n",
      "tensor([ 2.8723,  3.5605, -3.0358])\n",
      "tensor([ 2.8726,  3.5609, -3.0362])\n",
      "tensor([ 2.8729,  3.5613, -3.0366])\n",
      "tensor([ 2.8732,  3.5617, -3.0370])\n",
      "tensor([ 2.8735,  3.5621, -3.0373])\n",
      "tensor([ 2.8738,  3.5624, -3.0377])\n",
      "tensor([ 2.8741,  3.5628, -3.0380])\n",
      "tensor([ 2.8744,  3.5632, -3.0384])\n",
      "tensor([ 2.8747,  3.5635, -3.0387])\n",
      "tensor([ 2.8750,  3.5639, -3.0391])\n",
      "tensor([ 2.8752,  3.5643, -3.0394])\n",
      "tensor([ 2.8755,  3.5646, -3.0398])\n",
      "tensor([ 2.8758,  3.5650, -3.0401])\n",
      "tensor([ 2.8761,  3.5653, -3.0405])\n",
      "tensor([ 2.8764,  3.5657, -3.0408])\n",
      "tensor([ 2.8766,  3.5660, -3.0411])\n",
      "tensor([ 2.8769,  3.5664, -3.0415])\n",
      "tensor([ 2.8772,  3.5667, -3.0418])\n",
      "tensor([ 2.8774,  3.5670, -3.0421])\n",
      "tensor([ 2.8777,  3.5674, -3.0424])\n",
      "tensor([ 2.8780,  3.5677, -3.0428])\n",
      "tensor([ 2.8782,  3.5680, -3.0431])\n",
      "tensor([ 2.8785,  3.5684, -3.0434])\n",
      "tensor([ 2.8787,  3.5687, -3.0437])\n",
      "tensor([ 2.8790,  3.5690, -3.0440])\n",
      "tensor([ 2.8792,  3.5693, -3.0443])\n",
      "tensor([ 2.8795,  3.5696, -3.0446])\n",
      "tensor([ 2.8797,  3.5700, -3.0449])\n",
      "tensor([ 2.8800,  3.5703, -3.0452])\n",
      "tensor([ 2.8802,  3.5706, -3.0455])\n",
      "tensor([ 2.8804,  3.5709, -3.0458])\n",
      "tensor([ 2.8807,  3.5712, -3.0461])\n",
      "tensor([ 2.8809,  3.5715, -3.0464])\n",
      "tensor([ 2.8811,  3.5718, -3.0467])\n",
      "tensor([ 2.8814,  3.5721, -3.0469])\n",
      "tensor([ 2.8816,  3.5724, -3.0472])\n",
      "tensor([ 2.8818,  3.5727, -3.0475])\n",
      "tensor([ 2.8821,  3.5729, -3.0478])\n",
      "tensor([ 2.8823,  3.5732, -3.0480])\n",
      "tensor([ 2.8825,  3.5735, -3.0483])\n",
      "tensor([ 2.8827,  3.5738, -3.0486])\n",
      "tensor([ 2.8829,  3.5741, -3.0488])\n",
      "tensor([ 2.8831,  3.5743, -3.0491])\n",
      "tensor([ 2.8834,  3.5746, -3.0494])\n",
      "tensor([ 2.8836,  3.5749, -3.0496])\n",
      "tensor([ 2.8838,  3.5751, -3.0499])\n",
      "tensor([ 2.8840,  3.5754, -3.0501])\n",
      "tensor([ 2.8842,  3.5757, -3.0504])\n",
      "tensor([ 2.8844,  3.5759, -3.0506])\n",
      "tensor([ 2.8846,  3.5762, -3.0509])\n",
      "tensor([ 2.8848,  3.5765, -3.0511])\n",
      "tensor([ 2.8850,  3.5767, -3.0514])\n",
      "tensor([ 2.8852,  3.5770, -3.0516])\n",
      "tensor([ 2.8854,  3.5772, -3.0519])\n",
      "tensor([ 2.8856,  3.5775, -3.0521])\n",
      "tensor([ 2.8858,  3.5777, -3.0523])\n",
      "tensor([ 2.8860,  3.5779, -3.0526])\n",
      "tensor([ 2.8862,  3.5782, -3.0528])\n",
      "tensor([ 2.8863,  3.5784, -3.0530])\n",
      "tensor([ 2.8865,  3.5787, -3.0532])\n",
      "tensor([ 2.8867,  3.5789, -3.0535])\n",
      "tensor([ 2.8869,  3.5791, -3.0537])\n",
      "tensor([ 2.8871,  3.5794, -3.0539])\n",
      "tensor([ 2.8873,  3.5796, -3.0541])\n",
      "tensor([ 2.8874,  3.5798, -3.0544])\n",
      "tensor([ 2.8876,  3.5801, -3.0546])\n",
      "tensor([ 2.8878,  3.5803, -3.0548])\n",
      "tensor([ 2.8880,  3.5805, -3.0550])\n",
      "tensor([ 2.8881,  3.5807, -3.0552])\n",
      "tensor([ 2.8883,  3.5809, -3.0554])\n",
      "tensor([ 2.8885,  3.5812, -3.0556])\n",
      "tensor([ 2.8886,  3.5814, -3.0558])\n",
      "tensor([ 2.8888,  3.5816, -3.0560])\n",
      "tensor([ 2.8890,  3.5818, -3.0562])\n",
      "tensor([ 2.8891,  3.5820, -3.0564])\n",
      "tensor([ 2.8893,  3.5822, -3.0566])\n",
      "tensor([ 2.8894,  3.5824, -3.0568])\n",
      "tensor([ 2.8896,  3.5826, -3.0570])\n",
      "tensor([ 2.8898,  3.5828, -3.0572])\n",
      "tensor([ 2.8899,  3.5830, -3.0574])\n",
      "tensor([ 2.8901,  3.5832, -3.0576])\n",
      "tensor([ 2.8902,  3.5834, -3.0578])\n",
      "tensor([ 2.8904,  3.5836, -3.0580])\n",
      "tensor([ 2.8905,  3.5838, -3.0582])\n",
      "tensor([ 2.8907,  3.5840, -3.0583])\n",
      "tensor([ 2.8908,  3.5842, -3.0585])\n",
      "tensor([ 2.8910,  3.5844, -3.0587])\n",
      "tensor([ 2.8911,  3.5846, -3.0589])\n",
      "tensor([ 2.8913,  3.5847, -3.0591])\n",
      "tensor([ 2.8914,  3.5849, -3.0592])\n",
      "tensor([ 2.8916,  3.5851, -3.0594])\n",
      "tensor([ 2.8917,  3.5853, -3.0596])\n",
      "tensor([ 2.8918,  3.5855, -3.0598])\n",
      "tensor([ 2.8920,  3.5857, -3.0599])\n",
      "tensor([ 2.8921,  3.5858, -3.0601])\n",
      "tensor([ 2.8922,  3.5860, -3.0603])\n",
      "tensor([ 2.8924,  3.5862, -3.0604])\n",
      "tensor([ 2.8925,  3.5863, -3.0606])\n",
      "tensor([ 2.8926,  3.5865, -3.0608])\n",
      "tensor([ 2.8928,  3.5867, -3.0609])\n",
      "tensor([ 2.8929,  3.5869, -3.0611])\n",
      "tensor([ 2.8930,  3.5870, -3.0612])\n",
      "tensor([ 2.8932,  3.5872, -3.0614])\n",
      "tensor([ 2.8933,  3.5874, -3.0616])\n",
      "tensor([ 2.8934,  3.5875, -3.0617])\n",
      "tensor([ 2.8935,  3.5877, -3.0619])\n",
      "tensor([ 2.8937,  3.5878, -3.0620])\n",
      "tensor([ 2.8938,  3.5880, -3.0622])\n",
      "tensor([ 2.8939,  3.5881, -3.0623])\n",
      "tensor([ 2.8940,  3.5883, -3.0625])\n",
      "tensor([ 2.8942,  3.5885, -3.0626])\n",
      "tensor([ 2.8943,  3.5886, -3.0628])\n",
      "tensor([ 2.8944,  3.5888, -3.0629])\n",
      "tensor([ 2.8945,  3.5889, -3.0630])\n",
      "tensor([ 2.8946,  3.5891, -3.0632])\n",
      "tensor([ 2.8947,  3.5892, -3.0633])\n",
      "tensor([ 2.8949,  3.5894, -3.0635])\n",
      "tensor([ 2.8950,  3.5895, -3.0636])\n",
      "tensor([ 2.8951,  3.5896, -3.0638])\n",
      "tensor([ 2.8952,  3.5898, -3.0639])\n",
      "tensor([ 2.8953,  3.5899, -3.0640])\n",
      "tensor([ 2.8954,  3.5901, -3.0642])\n",
      "tensor([ 2.8955,  3.5902, -3.0643])\n",
      "tensor([ 2.8956,  3.5904, -3.0644])\n",
      "tensor([ 2.8957,  3.5905, -3.0646])\n",
      "tensor([ 2.8958,  3.5906, -3.0647])\n",
      "tensor([ 2.8959,  3.5908, -3.0648])\n",
      "tensor([ 2.8960,  3.5909, -3.0649])\n",
      "tensor([ 2.8962,  3.5910, -3.0651])\n",
      "tensor([ 2.8963,  3.5912, -3.0652])\n",
      "tensor([ 2.8964,  3.5913, -3.0653])\n",
      "tensor([ 2.8965,  3.5914, -3.0654])\n",
      "tensor([ 2.8966,  3.5915, -3.0656])\n",
      "tensor([ 2.8967,  3.5917, -3.0657])\n",
      "tensor([ 2.8968,  3.5918, -3.0658])\n",
      "tensor([ 2.8968,  3.5919, -3.0659])\n",
      "tensor([ 2.8969,  3.5920, -3.0660])\n",
      "tensor([ 2.8970,  3.5922, -3.0662])\n",
      "tensor([ 2.8971,  3.5923, -3.0663])\n",
      "tensor([ 2.8972,  3.5924, -3.0664])\n",
      "tensor([ 2.8973,  3.5925, -3.0665])\n",
      "tensor([ 2.8974,  3.5927, -3.0666])\n",
      "tensor([ 2.8975,  3.5928, -3.0667])\n",
      "tensor([ 2.8976,  3.5929, -3.0668])\n",
      "tensor([ 2.8977,  3.5930, -3.0669])\n",
      "tensor([ 2.8978,  3.5931, -3.0671])\n",
      "tensor([ 2.8979,  3.5932, -3.0672])\n",
      "tensor([ 2.8980,  3.5933, -3.0673])\n",
      "tensor([ 2.8980,  3.5935, -3.0674])\n",
      "tensor([ 2.8981,  3.5936, -3.0675])\n",
      "tensor([ 2.8982,  3.5937, -3.0676])\n",
      "tensor([ 2.8983,  3.5938, -3.0677])\n",
      "tensor([ 2.8984,  3.5939, -3.0678])\n",
      "tensor([ 2.8985,  3.5940, -3.0679])\n",
      "tensor([ 2.8985,  3.5941, -3.0680])\n",
      "tensor([ 2.8986,  3.5942, -3.0681])\n",
      "tensor([ 2.8987,  3.5943, -3.0682])\n",
      "tensor([ 2.8988,  3.5944, -3.0683])\n",
      "tensor([ 2.8989,  3.5945, -3.0684])\n",
      "tensor([ 2.8990,  3.5946, -3.0685])\n",
      "tensor([ 2.8990,  3.5947, -3.0686])\n",
      "tensor([ 2.8991,  3.5948, -3.0687])\n",
      "tensor([ 2.8992,  3.5949, -3.0688])\n",
      "tensor([ 2.8993,  3.5950, -3.0689])\n",
      "tensor([ 2.8993,  3.5951, -3.0690])\n",
      "tensor([ 2.8994,  3.5952, -3.0691])\n",
      "tensor([ 2.8995,  3.5953, -3.0692])\n",
      "tensor([ 2.8996,  3.5954, -3.0692])\n",
      "tensor([ 2.8996,  3.5955, -3.0693])\n",
      "tensor([ 2.8997,  3.5956, -3.0694])\n",
      "tensor([ 2.8998,  3.5957, -3.0695])\n",
      "tensor([ 2.8999,  3.5958, -3.0696])\n",
      "tensor([ 2.8999,  3.5959, -3.0697])\n",
      "tensor([ 2.9000,  3.5960, -3.0698])\n",
      "tensor([ 2.9001,  3.5961, -3.0699])\n",
      "tensor([ 2.9001,  3.5962, -3.0700])\n",
      "tensor([ 2.9002,  3.5962, -3.0700])\n",
      "tensor([ 2.9003,  3.5963, -3.0701])\n",
      "tensor([ 2.9003,  3.5964, -3.0702])\n",
      "tensor([ 2.9004,  3.5965, -3.0703])\n",
      "tensor([ 2.9005,  3.5966, -3.0704])\n",
      "tensor([ 2.9005,  3.5967, -3.0704])\n",
      "tensor([ 2.9006,  3.5968, -3.0705])\n",
      "tensor([ 2.9007,  3.5968, -3.0706])\n",
      "tensor([ 2.9007,  3.5969, -3.0707])\n",
      "tensor([ 2.9008,  3.5970, -3.0708])\n",
      "tensor([ 2.9009,  3.5971, -3.0708])\n",
      "tensor([ 2.9009,  3.5972, -3.0709])\n",
      "tensor([ 2.9010,  3.5972, -3.0710])\n",
      "tensor([ 2.9010,  3.5973, -3.0711])\n",
      "tensor([ 2.9011,  3.5974, -3.0711])\n",
      "tensor([ 2.9012,  3.5975, -3.0712])\n",
      "tensor([ 2.9012,  3.5976, -3.0713])\n",
      "tensor([ 2.9013,  3.5976, -3.0714])\n",
      "tensor([ 2.9013,  3.5977, -3.0714])\n",
      "tensor([ 2.9014,  3.5978, -3.0715])\n",
      "tensor([ 2.9015,  3.5979, -3.0716])\n",
      "tensor([ 2.9015,  3.5979, -3.0717])\n",
      "tensor([ 2.9016,  3.5980, -3.0717])\n",
      "tensor([ 2.9016,  3.5981, -3.0718])\n",
      "tensor([ 2.9017,  3.5982, -3.0719])\n",
      "tensor([ 2.9017,  3.5982, -3.0719])\n",
      "tensor([ 2.9018,  3.5983, -3.0720])\n",
      "tensor([ 2.9018,  3.5984, -3.0721])\n",
      "tensor([ 2.9019,  3.5984, -3.0721])\n",
      "tensor([ 2.9020,  3.5985, -3.0722])\n",
      "tensor([ 2.9020,  3.5986, -3.0723])\n",
      "tensor([ 2.9021,  3.5986, -3.0723])\n",
      "tensor([ 2.9021,  3.5987, -3.0724])\n",
      "tensor([ 2.9022,  3.5988, -3.0725])\n",
      "tensor([ 2.9022,  3.5989, -3.0725])\n",
      "tensor([ 2.9023,  3.5989, -3.0726])\n",
      "tensor([ 2.9023,  3.5990, -3.0727])\n",
      "tensor([ 2.9024,  3.5990, -3.0727])\n",
      "tensor([ 2.9024,  3.5991, -3.0728])\n",
      "tensor([ 2.9025,  3.5992, -3.0728])\n",
      "tensor([ 2.9025,  3.5992, -3.0729])\n",
      "tensor([ 2.9026,  3.5993, -3.0730])\n",
      "tensor([ 2.9026,  3.5994, -3.0730])\n",
      "tensor([ 2.9027,  3.5994, -3.0731])\n",
      "tensor([ 2.9027,  3.5995, -3.0731])\n",
      "tensor([ 2.9028,  3.5995, -3.0732])\n",
      "tensor([ 2.9028,  3.5996, -3.0732])\n",
      "tensor([ 2.9029,  3.5997, -3.0733])\n",
      "tensor([ 2.9029,  3.5997, -3.0734])\n",
      "tensor([ 2.9029,  3.5998, -3.0734])\n",
      "tensor([ 2.9030,  3.5998, -3.0735])\n",
      "tensor([ 2.9030,  3.5999, -3.0735])\n",
      "tensor([ 2.9031,  3.6000, -3.0736])\n",
      "tensor([ 2.9031,  3.6000, -3.0736])\n",
      "tensor([ 2.9032,  3.6001, -3.0737])\n",
      "tensor([ 2.9032,  3.6001, -3.0737])\n",
      "tensor([ 2.9033,  3.6002, -3.0738])\n",
      "tensor([ 2.9033,  3.6002, -3.0738])\n",
      "tensor([ 2.9033,  3.6003, -3.0739])\n",
      "tensor([ 2.9034,  3.6003, -3.0740])\n",
      "tensor([ 2.9034,  3.6004, -3.0740])\n",
      "tensor([ 2.9035,  3.6005, -3.0741])\n",
      "tensor([ 2.9035,  3.6005, -3.0741])\n",
      "tensor([ 2.9035,  3.6006, -3.0742])\n",
      "tensor([ 2.9036,  3.6006, -3.0742])\n",
      "tensor([ 2.9036,  3.6007, -3.0743])\n",
      "tensor([ 2.9037,  3.6007, -3.0743])\n",
      "tensor([ 2.9037,  3.6008, -3.0743])\n",
      "tensor([ 2.9037,  3.6008, -3.0744])\n",
      "tensor([ 2.9038,  3.6009, -3.0744])\n",
      "tensor([ 2.9038,  3.6009, -3.0745])\n",
      "tensor([ 2.9039,  3.6010, -3.0745])\n",
      "tensor([ 2.9039,  3.6010, -3.0746])\n",
      "tensor([ 2.9039,  3.6011, -3.0746])\n",
      "tensor([ 2.9040,  3.6011, -3.0747])\n",
      "tensor([ 2.9040,  3.6012, -3.0747])\n",
      "tensor([ 2.9040,  3.6012, -3.0748])\n",
      "tensor([ 2.9041,  3.6012, -3.0748])\n",
      "tensor([ 2.9041,  3.6013, -3.0749])\n",
      "tensor([ 2.9042,  3.6013, -3.0749])\n",
      "tensor([ 2.9042,  3.6014, -3.0749])\n",
      "tensor([ 2.9042,  3.6014, -3.0750])\n",
      "tensor([ 2.9043,  3.6015, -3.0750])\n",
      "tensor([ 2.9043,  3.6015, -3.0751])\n",
      "tensor([ 2.9043,  3.6016, -3.0751])\n",
      "tensor([ 2.9044,  3.6016, -3.0752])\n",
      "tensor([ 2.9044,  3.6016, -3.0752])\n",
      "tensor([ 2.9044,  3.6017, -3.0752])\n",
      "tensor([ 2.9045,  3.6017, -3.0753])\n",
      "tensor([ 2.9045,  3.6018, -3.0753])\n",
      "tensor([ 2.9045,  3.6018, -3.0754])\n",
      "tensor([ 2.9046,  3.6019, -3.0754])\n",
      "tensor([ 2.9046,  3.6019, -3.0754])\n",
      "tensor([ 2.9046,  3.6019, -3.0755])\n",
      "tensor([ 2.9046,  3.6020, -3.0755])\n",
      "tensor([ 2.9047,  3.6020, -3.0755])\n",
      "tensor([ 2.9047,  3.6021, -3.0756])\n",
      "tensor([ 2.9047,  3.6021, -3.0756])\n",
      "tensor([ 2.9048,  3.6021, -3.0757])\n",
      "tensor([ 2.9048,  3.6022, -3.0757])\n",
      "tensor([ 2.9048,  3.6022, -3.0757])\n",
      "tensor([ 2.9049,  3.6023, -3.0758])\n",
      "tensor([ 2.9049,  3.6023, -3.0758])\n",
      "tensor([ 2.9049,  3.6023, -3.0758])\n",
      "tensor([ 2.9049,  3.6024, -3.0759])\n",
      "tensor([ 2.9050,  3.6024, -3.0759])\n",
      "tensor([ 2.9050,  3.6024, -3.0759])\n",
      "tensor([ 2.9050,  3.6025, -3.0760])\n",
      "tensor([ 2.9051,  3.6025, -3.0760])\n",
      "tensor([ 2.9051,  3.6025, -3.0761])\n",
      "tensor([ 2.9051,  3.6026, -3.0761])\n",
      "tensor([ 2.9051,  3.6026, -3.0761])\n",
      "tensor([ 2.9052,  3.6027, -3.0762])\n",
      "tensor([ 2.9052,  3.6027, -3.0762])\n",
      "tensor([ 2.9052,  3.6027, -3.0762])\n",
      "tensor([ 2.9052,  3.6028, -3.0762])\n",
      "tensor([ 2.9053,  3.6028, -3.0763])\n",
      "tensor([ 2.9053,  3.6028, -3.0763])\n",
      "tensor([ 2.9053,  3.6029, -3.0763])\n",
      "tensor([ 2.9053,  3.6029, -3.0764])\n",
      "tensor([ 2.9054,  3.6029, -3.0764])\n",
      "tensor([ 2.9054,  3.6030, -3.0764])\n",
      "tensor([ 2.9054,  3.6030, -3.0765])\n",
      "tensor([ 2.9054,  3.6030, -3.0765])\n",
      "tensor([ 2.9055,  3.6030, -3.0765])\n",
      "tensor([ 2.9055,  3.6031, -3.0766])\n",
      "tensor([ 2.9055,  3.6031, -3.0766])\n",
      "tensor([ 2.9055,  3.6031, -3.0766])\n",
      "tensor([ 2.9056,  3.6032, -3.0766])\n",
      "tensor([ 2.9056,  3.6032, -3.0767])\n",
      "tensor([ 2.9056,  3.6032, -3.0767])\n",
      "tensor([ 2.9056,  3.6033, -3.0767])\n",
      "tensor([ 2.9057,  3.6033, -3.0768])\n",
      "tensor([ 2.9057,  3.6033, -3.0768])\n",
      "tensor([ 2.9057,  3.6033, -3.0768])\n",
      "tensor([ 2.9057,  3.6034, -3.0768])\n",
      "tensor([ 2.9057,  3.6034, -3.0769])\n",
      "tensor([ 2.9058,  3.6034, -3.0769])\n",
      "tensor([ 2.9058,  3.6035, -3.0769])\n",
      "tensor([ 2.9058,  3.6035, -3.0769])\n",
      "tensor([ 2.9058,  3.6035, -3.0770])\n",
      "tensor([ 2.9059,  3.6035, -3.0770])\n",
      "tensor([ 2.9059,  3.6036, -3.0770])\n",
      "tensor([ 2.9059,  3.6036, -3.0771])\n",
      "tensor([ 2.9059,  3.6036, -3.0771])\n",
      "tensor([ 2.9059,  3.6037, -3.0771])\n",
      "tensor([ 2.9060,  3.6037, -3.0771])\n",
      "tensor([ 2.9060,  3.6037, -3.0772])\n",
      "tensor([ 2.9060,  3.6037, -3.0772])\n",
      "tensor([ 2.9060,  3.6038, -3.0772])\n",
      "tensor([ 2.9060,  3.6038, -3.0772])\n",
      "tensor([ 2.9061,  3.6038, -3.0772])\n",
      "tensor([ 2.9061,  3.6038, -3.0773])\n",
      "tensor([ 2.9061,  3.6039, -3.0773])\n",
      "tensor([ 2.9061,  3.6039, -3.0773])\n",
      "tensor([ 2.9061,  3.6039, -3.0773])\n",
      "tensor([ 2.9062,  3.6039, -3.0774])\n",
      "tensor([ 2.9062,  3.6040, -3.0774])\n",
      "tensor([ 2.9062,  3.6040, -3.0774])\n",
      "tensor([ 2.9062,  3.6040, -3.0774])\n",
      "tensor([ 2.9062,  3.6040, -3.0775])\n",
      "tensor([ 2.9062,  3.6040, -3.0775])\n",
      "tensor([ 2.9063,  3.6041, -3.0775])\n",
      "tensor([ 2.9063,  3.6041, -3.0775])\n",
      "tensor([ 2.9063,  3.6041, -3.0775])\n",
      "tensor([ 2.9063,  3.6041, -3.0776])\n",
      "tensor([ 2.9063,  3.6042, -3.0776])\n",
      "tensor([ 2.9064,  3.6042, -3.0776])\n",
      "tensor([ 2.9064,  3.6042, -3.0776])\n",
      "tensor([ 2.9064,  3.6042, -3.0776])\n",
      "tensor([ 2.9064,  3.6042, -3.0777])\n",
      "tensor([ 2.9064,  3.6043, -3.0777])\n",
      "tensor([ 2.9064,  3.6043, -3.0777])\n",
      "tensor([ 2.9065,  3.6043, -3.0777])\n",
      "tensor([ 2.9065,  3.6043, -3.0777])\n",
      "tensor([ 2.9065,  3.6043, -3.0778])\n",
      "tensor([ 2.9065,  3.6044, -3.0778])\n",
      "tensor([ 2.9065,  3.6044, -3.0778])\n",
      "tensor([ 2.9065,  3.6044, -3.0778])\n",
      "tensor([ 2.9065,  3.6044, -3.0778])\n",
      "tensor([ 2.9066,  3.6044, -3.0779])\n",
      "tensor([ 2.9066,  3.6045, -3.0779])\n",
      "tensor([ 2.9066,  3.6045, -3.0779])\n",
      "tensor([ 2.9066,  3.6045, -3.0779])\n",
      "tensor([ 2.9066,  3.6045, -3.0779])\n",
      "tensor([ 2.9066,  3.6045, -3.0780])\n",
      "tensor([ 2.9067,  3.6046, -3.0780])\n",
      "tensor([ 2.9067,  3.6046, -3.0780])\n",
      "tensor([ 2.9067,  3.6046, -3.0780])\n",
      "tensor([ 2.9067,  3.6046, -3.0780])\n",
      "tensor([ 2.9067,  3.6046, -3.0780])\n",
      "tensor([ 2.9067,  3.6047, -3.0781])\n",
      "tensor([ 2.9067,  3.6047, -3.0781])\n",
      "tensor([ 2.9068,  3.6047, -3.0781])\n",
      "tensor([ 2.9068,  3.6047, -3.0781])\n",
      "tensor([ 2.9068,  3.6047, -3.0781])\n",
      "tensor([ 2.9068,  3.6047, -3.0781])\n",
      "tensor([ 2.9068,  3.6048, -3.0782])\n",
      "tensor([ 2.9068,  3.6048, -3.0782])\n",
      "tensor([ 2.9068,  3.6048, -3.0782])\n",
      "tensor([ 2.9068,  3.6048, -3.0782])\n",
      "tensor([ 2.9069,  3.6048, -3.0782])\n",
      "tensor([ 2.9069,  3.6048, -3.0782])\n",
      "tensor([ 2.9069,  3.6049, -3.0783])\n",
      "tensor([ 2.9069,  3.6049, -3.0783])\n",
      "tensor([ 2.9069,  3.6049, -3.0783])\n",
      "tensor([ 2.9069,  3.6049, -3.0783])\n",
      "tensor([ 2.9069,  3.6049, -3.0783])\n",
      "tensor([ 2.9069,  3.6049, -3.0783])\n",
      "tensor([ 2.9070,  3.6050, -3.0784])\n",
      "tensor([ 2.9070,  3.6050, -3.0784])\n",
      "tensor([ 2.9070,  3.6050, -3.0784])\n",
      "tensor([ 2.9070,  3.6050, -3.0784])\n",
      "tensor([ 2.9070,  3.6050, -3.0784])\n",
      "tensor([ 2.9070,  3.6050, -3.0784])\n",
      "tensor([ 2.9070,  3.6050, -3.0784])\n",
      "tensor([ 2.9070,  3.6051, -3.0785])\n",
      "tensor([ 2.9071,  3.6051, -3.0785])\n",
      "tensor([ 2.9071,  3.6051, -3.0785])\n",
      "tensor([ 2.9071,  3.6051, -3.0785])\n",
      "tensor([ 2.9071,  3.6051, -3.0785])\n",
      "tensor([ 2.9071,  3.6051, -3.0785])\n",
      "tensor([ 2.9071,  3.6052, -3.0785])\n",
      "tensor([ 2.9071,  3.6052, -3.0785])\n",
      "tensor([ 2.9071,  3.6052, -3.0786])\n",
      "tensor([ 2.9071,  3.6052, -3.0786])\n",
      "tensor([ 2.9072,  3.6052, -3.0786])\n",
      "tensor([ 2.9072,  3.6052, -3.0786])\n",
      "tensor([ 2.9072,  3.6052, -3.0786])\n",
      "tensor([ 2.9072,  3.6052, -3.0786])\n",
      "tensor([ 2.9072,  3.6053, -3.0786])\n",
      "tensor([ 2.9072,  3.6053, -3.0787])\n",
      "tensor([ 2.9072,  3.6053, -3.0787])\n",
      "tensor([ 2.9072,  3.6053, -3.0787])\n",
      "tensor([ 2.9072,  3.6053, -3.0787])\n",
      "tensor([ 2.9072,  3.6053, -3.0787])\n",
      "tensor([ 2.9073,  3.6053, -3.0787])\n",
      "tensor([ 2.9073,  3.6053, -3.0787])\n",
      "tensor([ 2.9073,  3.6054, -3.0787])\n",
      "tensor([ 2.9073,  3.6054, -3.0787])\n",
      "tensor([ 2.9073,  3.6054, -3.0788])\n",
      "tensor([ 2.9073,  3.6054, -3.0788])\n",
      "tensor([ 2.9073,  3.6054, -3.0788])\n",
      "tensor([ 2.9073,  3.6054, -3.0788])\n",
      "tensor([ 2.9073,  3.6054, -3.0788])\n",
      "tensor([ 2.9073,  3.6054, -3.0788])\n",
      "tensor([ 2.9074,  3.6055, -3.0788])\n",
      "tensor([ 2.9074,  3.6055, -3.0788])\n",
      "tensor([ 2.9074,  3.6055, -3.0788])\n",
      "tensor([ 2.9074,  3.6055, -3.0789])\n",
      "tensor([ 2.9074,  3.6055, -3.0789])\n",
      "tensor([ 2.9074,  3.6055, -3.0789])\n",
      "tensor([ 2.9074,  3.6055, -3.0789])\n",
      "tensor([ 2.9074,  3.6055, -3.0789])\n",
      "tensor([ 2.9074,  3.6055, -3.0789])\n",
      "tensor([ 2.9074,  3.6056, -3.0789])\n",
      "tensor([ 2.9074,  3.6056, -3.0789])\n",
      "tensor([ 2.9074,  3.6056, -3.0789])\n",
      "tensor([ 2.9075,  3.6056, -3.0790])\n",
      "tensor([ 2.9075,  3.6056, -3.0790])\n",
      "tensor([ 2.9075,  3.6056, -3.0790])\n",
      "tensor([ 2.9075,  3.6056, -3.0790])\n",
      "tensor([ 2.9075,  3.6056, -3.0790])\n",
      "tensor([ 2.9075,  3.6056, -3.0790])\n",
      "tensor([ 2.9075,  3.6056, -3.0790])\n",
      "tensor([ 2.9075,  3.6057, -3.0790])\n",
      "tensor([ 2.9075,  3.6057, -3.0790])\n",
      "tensor([ 2.9075,  3.6057, -3.0790])\n",
      "tensor([ 2.9075,  3.6057, -3.0791])\n",
      "tensor([ 2.9075,  3.6057, -3.0791])\n",
      "tensor([ 2.9075,  3.6057, -3.0791])\n",
      "tensor([ 2.9076,  3.6057, -3.0791])\n",
      "tensor([ 2.9076,  3.6057, -3.0791])\n",
      "tensor([ 2.9076,  3.6057, -3.0791])\n",
      "tensor([ 2.9076,  3.6057, -3.0791])\n",
      "tensor([ 2.9076,  3.6058, -3.0791])\n",
      "tensor([ 2.9076,  3.6058, -3.0791])\n",
      "tensor([ 2.9076,  3.6058, -3.0791])\n",
      "tensor([ 2.9076,  3.6058, -3.0791])\n",
      "tensor([ 2.9076,  3.6058, -3.0791])\n",
      "tensor([ 2.9076,  3.6058, -3.0792])\n",
      "tensor([ 2.9076,  3.6058, -3.0792])\n",
      "tensor([ 2.9076,  3.6058, -3.0792])\n",
      "tensor([ 2.9076,  3.6058, -3.0792])\n",
      "tensor([ 2.9076,  3.6058, -3.0792])\n",
      "tensor([ 2.9077,  3.6058, -3.0792])\n",
      "tensor([ 2.9077,  3.6058, -3.0792])\n",
      "tensor([ 2.9077,  3.6059, -3.0792])\n",
      "tensor([ 2.9077,  3.6059, -3.0792])\n",
      "tensor([ 2.9077,  3.6059, -3.0792])\n",
      "tensor([ 2.9077,  3.6059, -3.0792])\n",
      "tensor([ 2.9077,  3.6059, -3.0792])\n",
      "tensor([ 2.9077,  3.6059, -3.0792])\n",
      "tensor([ 2.9077,  3.6059, -3.0793])\n",
      "tensor([ 2.9077,  3.6059, -3.0793])\n",
      "tensor([ 2.9077,  3.6059, -3.0793])\n",
      "tensor([ 2.9077,  3.6059, -3.0793])\n",
      "tensor([ 2.9077,  3.6059, -3.0793])\n",
      "tensor([ 2.9077,  3.6059, -3.0793])\n",
      "tensor([ 2.9077,  3.6060, -3.0793])\n",
      "tensor([ 2.9077,  3.6060, -3.0793])\n",
      "tensor([ 2.9077,  3.6060, -3.0793])\n",
      "tensor([ 2.9077,  3.6060, -3.0793])\n",
      "tensor([ 2.9078,  3.6060, -3.0793])\n",
      "tensor([ 2.9078,  3.6060, -3.0793])\n",
      "tensor([ 2.9078,  3.6060, -3.0793])\n",
      "tensor([ 2.9078,  3.6060, -3.0794])\n",
      "tensor([ 2.9078,  3.6060, -3.0794])\n",
      "tensor([ 2.9078,  3.6060, -3.0794])\n",
      "tensor([ 2.9078,  3.6060, -3.0794])\n",
      "tensor([ 2.9078,  3.6060, -3.0794])\n",
      "tensor([ 2.9078,  3.6060, -3.0794])\n",
      "tensor([ 2.9078,  3.6061, -3.0794])\n",
      "tensor([ 2.9078,  3.6061, -3.0794])\n",
      "tensor([ 2.9078,  3.6061, -3.0794])\n",
      "tensor([ 2.9078,  3.6061, -3.0794])\n",
      "tensor([ 2.9078,  3.6061, -3.0794])\n",
      "tensor([ 2.9078,  3.6061, -3.0794])\n",
      "tensor([ 2.9078,  3.6061, -3.0794])\n",
      "tensor([ 2.9078,  3.6061, -3.0794])\n",
      "tensor([ 2.9079,  3.6061, -3.0794])\n",
      "tensor([ 2.9079,  3.6061, -3.0794])\n",
      "tensor([ 2.9079,  3.6061, -3.0794])\n",
      "tensor([ 2.9079,  3.6061, -3.0794])\n",
      "tensor([ 2.9079,  3.6061, -3.0795])\n",
      "tensor([ 2.9079,  3.6061, -3.0795])\n",
      "tensor([ 2.9079,  3.6061, -3.0795])\n",
      "tensor([ 2.9079,  3.6061, -3.0795])\n",
      "tensor([ 2.9079,  3.6061, -3.0795])\n",
      "tensor([ 2.9079,  3.6062, -3.0795])\n",
      "tensor([ 2.9079,  3.6062, -3.0795])\n",
      "tensor([ 2.9079,  3.6062, -3.0795])\n",
      "tensor([ 2.9079,  3.6062, -3.0795])\n",
      "tensor([ 2.9079,  3.6062, -3.0795])\n",
      "tensor([ 2.9079,  3.6062, -3.0795])\n",
      "tensor([ 2.9079,  3.6062, -3.0795])\n",
      "tensor([ 2.9079,  3.6062, -3.0795])\n",
      "tensor([ 2.9079,  3.6062, -3.0795])\n",
      "tensor([ 2.9079,  3.6062, -3.0795])\n",
      "tensor([ 2.9079,  3.6062, -3.0795])\n",
      "tensor([ 2.9079,  3.6062, -3.0795])\n",
      "tensor([ 2.9079,  3.6062, -3.0796])\n",
      "tensor([ 2.9079,  3.6062, -3.0796])\n",
      "tensor([ 2.9079,  3.6062, -3.0796])\n",
      "tensor([ 2.9079,  3.6062, -3.0796])\n",
      "tensor([ 2.9079,  3.6062, -3.0796])\n",
      "tensor([ 2.9079,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0796])\n",
      "tensor([ 2.9080,  3.6063, -3.0797])\n",
      "tensor([ 2.9080,  3.6063, -3.0797])\n",
      "tensor([ 2.9080,  3.6064, -3.0797])\n",
      "tensor([ 2.9080,  3.6064, -3.0797])\n",
      "tensor([ 2.9080,  3.6064, -3.0797])\n",
      "tensor([ 2.9080,  3.6064, -3.0797])\n",
      "tensor([ 2.9080,  3.6064, -3.0797])\n",
      "tensor([ 2.9080,  3.6064, -3.0797])\n",
      "tensor([ 2.9080,  3.6064, -3.0797])\n",
      "tensor([ 2.9080,  3.6064, -3.0797])\n",
      "tensor([ 2.9080,  3.6064, -3.0797])\n",
      "tensor([ 2.9080,  3.6064, -3.0797])\n",
      "tensor([ 2.9080,  3.6064, -3.0797])\n",
      "tensor([ 2.9080,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0797])\n",
      "tensor([ 2.9081,  3.6064, -3.0798])\n",
      "tensor([ 2.9081,  3.6064, -3.0798])\n",
      "tensor([ 2.9081,  3.6064, -3.0798])\n",
      "tensor([ 2.9081,  3.6065, -3.0798])\n",
      "tensor([ 2.9081,  3.6065, -3.0798])\n",
      "tensor([ 2.9081,  3.6065, -3.0798])\n",
      "tensor([ 2.9081,  3.6065, -3.0798])\n",
      "tensor([ 2.9081,  3.6065, -3.0798])\n",
      "tensor([ 2.9081,  3.6065, -3.0798])\n",
      "tensor([ 2.9081,  3.6065, -3.0798])\n",
      "tensor([ 2.9081,  3.6065, -3.0798])\n",
      "tensor([ 2.9081,  3.6065, -3.0798])\n",
      "tensor([ 2.9081,  3.6065, -3.0798])\n",
      "tensor([ 2.9081,  3.6065, -3.0798])\n",
      "tensor([ 2.9081,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0798])\n",
      "tensor([ 2.9082,  3.6065, -3.0799])\n",
      "tensor([ 2.9082,  3.6065, -3.0799])\n",
      "tensor([ 2.9082,  3.6065, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6066, -3.0799])\n",
      "tensor([ 2.9082,  3.6067, -3.0799])\n",
      "tensor([ 2.9082,  3.6067, -3.0799])\n",
      "tensor([ 2.9082,  3.6067, -3.0799])\n",
      "tensor([ 2.9082,  3.6067, -3.0799])\n",
      "tensor([ 2.9082,  3.6067, -3.0799])\n",
      "tensor([ 2.9082,  3.6067, -3.0800])\n",
      "tensor([ 2.9082,  3.6067, -3.0800])\n",
      "tensor([ 2.9082,  3.6067, -3.0800])\n",
      "tensor([ 2.9082,  3.6067, -3.0800])\n",
      "tensor([ 2.9082,  3.6067, -3.0800])\n",
      "tensor([ 2.9082,  3.6067, -3.0800])\n",
      "tensor([ 2.9082,  3.6067, -3.0800])\n",
      "tensor([ 2.9082,  3.6067, -3.0800])\n",
      "tensor([ 2.9082,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n",
      "tensor([ 2.9083,  3.6067, -3.0800])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAIN the model\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "LR = LogisticRegression() \n",
    "opt = GradientDescentOptimizer(LR)\n",
    "\n",
    "loss_vec = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    # add other stuff to e.g. keep track of the loss over time. \n",
    "\n",
    "    loss = LR.loss(X, y)\n",
    "    loss_vec.append(loss)\n",
    "\n",
    "    opt.step(X, y, alpha = 0.1, beta = 0.9)\n",
    "\n",
    "plt.plot(torch.arange(1, len(loss_vec) +1), loss_vec, color=\"black\")\n",
    "plt.semilogx()\n",
    "labs = plt.gca().set(xlabel = \"Number of Gradient Descent iterations\", ylabel=\"loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
